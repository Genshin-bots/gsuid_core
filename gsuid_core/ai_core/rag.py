"""æ¨¡åž‹çŸ¥è¯†åº“RAGç®¡ç†"""

import json
import uuid
import hashlib
from typing import Dict, List, Optional

from qdrant_client.models import Filter, Distance, MatchValue, PointStruct, VectorParams, FieldCondition
from qdrant_client.http.models.models import ScoredPoint

from gsuid_core.logger import logger
from gsuid_core.ai_core.embedding import DIMENSION, client, embedding_model

from .models import KnowledgePoint
from .register import _ENTITIES

# å…¨å±€çŸ¥è¯†é›†åˆåç§°
COLLECTION_NAME = "knowledge"


async def init_collection():
    """åˆå§‹åŒ–çŸ¥è¯†é›†åˆ"""
    if client is None:
        logger.debug("ðŸ§  [RAG] AIåŠŸèƒ½æœªå¯ç”¨ï¼Œè·³è¿‡é›†åˆåˆå§‹åŒ–")
        return

    if not await client.collection_exists(COLLECTION_NAME):
        logger.info(f"ðŸ§  [RAG] åˆ›å»ºæ–°é›†åˆ: {COLLECTION_NAME}")

        await client.create_collection(
            collection_name=COLLECTION_NAME,
            vectors_config=VectorParams(size=DIMENSION, distance=Distance.COSINE),
        )
    else:
        logger.info(f"ðŸ§  [RAG] é›†åˆå·²å­˜åœ¨: {COLLECTION_NAME}")


async def sync_knowledge():
    """åŒæ­¥çŸ¥è¯†åˆ°å‘é‡åº“"""
    if client is None or embedding_model is None:
        logger.debug("ðŸ§  [RAG] AIåŠŸèƒ½æœªå¯ç”¨ï¼Œè·³è¿‡åŒæ­¥")
        return

    logger.info("ðŸ§  [RAG] å¼€å§‹åŒæ­¥çŸ¥è¯†åº“...")

    # 1. èŽ·å–çŽ°æœ‰æ•°æ®
    existing_knowledge: Dict[str, Dict] = {}
    next_page_offset = None

    while True:
        records, next_page_offset = await client.scroll(
            collection_name=COLLECTION_NAME,
            limit=100,
            with_payload=True,
            with_vectors=False,
            offset=next_page_offset,
        )
        for record in records:
            if record.payload is None:
                continue
            id_str: Optional[str] = record.payload.get("id")
            if id_str:
                _t = {
                    "id": record.id,
                    "hash": record.payload.get("_hash"),
                }
                existing_knowledge[id_str] = _t

        if next_page_offset is None:
            break

    # 2. å‡†å¤‡æ–°æ•°æ®
    points_to_upsert = []
    local_ids = set()

    logger.info(f"ðŸ§  [RAG] æœ¬åœ°çŸ¥è¯†æ•°é‡: {len(_ENTITIES)}")
    logger.trace(f"ðŸ§  [RAG] æœ¬åœ°çŸ¥è¯†: {_ENTITIES}")
    for knowledge in _ENTITIES:
        id_str = knowledge["id"]
        local_ids.add(id_str)

        current_hash = calculate_knowledge_hash(knowledge)

        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
        is_new = id_str not in existing_knowledge
        is_modified = not is_new and existing_knowledge[id_str]["hash"] != current_hash

        if is_new or is_modified:
            action_str = "æ–°å¢ž" if is_new else "æ›´æ–°"
            logger.info(
                f"ðŸ§  [RAG] [{knowledge['plugin']}] [{action_str}] çŸ¥è¯†: {knowledge['category']}/{knowledge['title']}"
            )

            # ç”Ÿæˆå‘é‡
            text_to_embed = knowledge["content"]
            vector = list(embedding_model.embed([text_to_embed]))[0]

            # æž„å»ºpayload
            payload = knowledge.copy()
            payload["_hash"] = current_hash

            points_to_upsert.append(
                PointStruct(
                    id=get_knowledge_point_id(id_str),
                    vector=list(vector),
                    payload=payload,  # type: ignore
                )
            )

    # 3. æ‰§è¡Œæ›´æ–°
    if points_to_upsert:
        logger.info(f"ðŸ§  [RAG] å†™å…¥ {len(points_to_upsert)} ä¸ªçŸ¥è¯†ç‚¹...")
        await client.upsert(collection_name=COLLECTION_NAME, points=points_to_upsert)

    # 4. æ¸…ç†å·²åˆ é™¤çš„çŸ¥è¯†
    ids_to_delete = [
        existing_knowledge[id_str]["id"] for id_str in existing_knowledge.keys() if id_str not in local_ids
    ]
    if ids_to_delete:
        await client.delete(collection_name=COLLECTION_NAME, points_selector=ids_to_delete)
        logger.info(f"ðŸ§  [RAG] æ¸…ç† {len(ids_to_delete)} ä¸ªå·²åˆ é™¤çš„çŸ¥è¯†ç‚¹")

    logger.info("ðŸ§  [RAG] çŸ¥è¯†åº“åŒæ­¥å®Œæˆ\n")


async def query_knowledge(
    query: str,
    category: Optional[str] = None,
    plugin: Optional[str] = None,
    limit: int = 8,
    score_threshold: float = 0.44,
) -> List[ScoredPoint]:
    """æŸ¥è¯¢çŸ¥è¯†

    Args:
        query: ç”¨æˆ·æŸ¥è¯¢çš„è‡ªç„¶è¯­è¨€
        category: å¯é€‰ï¼Œé™å®šæŸ¥è¯¢çš„ç±»åˆ«
        plugin: å¯é€‰ï¼Œé™å®šæŸ¥è¯¢çš„æ’ä»¶
        limit: è¿”å›žç»“æžœæ•°é‡
        score_threshold: ç›¸ä¼¼åº¦åˆ†æ•°é˜ˆå€¼ï¼Œä½ŽäºŽæ­¤å€¼çš„ç»“æžœå°†è¢«è¿‡æ»¤

    Returns:
        ç›¸å…³çŸ¥è¯†åˆ—è¡¨
    """
    if client is None or embedding_model is None:
        logger.warning("ðŸ§  [RAG] AIåŠŸèƒ½æœªå¯ç”¨ï¼Œæ— æ³•æŸ¥è¯¢çŸ¥è¯†")
        return []

    logger.info(f"ðŸ§  [RAG] æŸ¥è¯¢çŸ¥è¯†: {query}")

    # ç”ŸæˆæŸ¥è¯¢å‘é‡
    query_vec = list(embedding_model.embed([query]))[0]

    # æž„å»ºè¿‡æ»¤æ¡ä»¶
    filter_condition = None
    conditions = []
    if category:
        conditions.append(
            FieldCondition(
                key="category",
                match=MatchValue(value=category),
            )
        )
    if plugin:
        conditions.append(
            FieldCondition(
                key="plugin",
                match=MatchValue(value=plugin),
            )
        )
    if conditions:
        filter_condition = Filter(must=conditions)

    # æŸ¥è¯¢å‘é‡åº“
    response = await client.query_points(
        collection_name=COLLECTION_NAME,
        query=list(query_vec),
        limit=limit,
        query_filter=filter_condition,
        with_payload=True,
    )

    # è¿‡æ»¤ä½Žåˆ†ç»“æžœ
    filtered_results: list[ScoredPoint] = [point for point in response.points if point.score >= score_threshold]

    logger.info(f"ðŸ§  [RAG] æŸ¥è¯¢å®Œæˆ: æ‰¾åˆ° {len(filtered_results)} ä¸ªç›¸å…³çŸ¥è¯† (é˜ˆå€¼: {score_threshold})")
    logger.trace(f"ðŸ§  [RAG] æŸ¥è¯¢ç»“æžœ: {filtered_results}")

    return filtered_results


def get_knowledge_point_id(id_str: str) -> str:
    """ç”ŸæˆçŸ¥è¯†ç‚¹çš„å”¯ä¸€ID

    Args:
        id_str: å”¯ä¸€æ ‡è¯†ç¬¦å­—ç¬¦ä¸²

    Returns:
        å”¯ä¸€çš„UUIDå­—ç¬¦ä¸²
    """
    return str(uuid.uuid5(uuid.NAMESPACE_DNS, id_str))


def calculate_knowledge_hash(knowledge: KnowledgePoint) -> str:
    """è®¡ç®—çŸ¥è¯†å†…å®¹çš„å“ˆå¸Œï¼Œç”¨äºŽæ£€æµ‹æ›´æ–°

    Args:
        knowledge: çŸ¥è¯†ç‚¹å¯¹è±¡

    Returns:
        MD5å“ˆå¸Œå€¼
    """
    json_str = json.dumps(knowledge, sort_keys=True, ensure_ascii=False)
    return hashlib.md5(json_str.encode("utf-8")).hexdigest()
