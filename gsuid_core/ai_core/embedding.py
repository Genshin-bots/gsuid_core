import os
import json
import uuid
import hashlib
from typing import TYPE_CHECKING, Union

if TYPE_CHECKING:
    from fastembed import TextEmbedding
    from qdrant_client import AsyncQdrantClient
    from qdrant_client.models import Distance, PointStruct, VectorParams

from gsuid_core.logger import logger
from gsuid_core.server import on_core_start
from gsuid_core.data_store import AI_CORE_PATH
from gsuid_core.ai_core.ai_config import ai_config

from .register import get_registered_tools

enable_ai: bool = ai_config.get_config("enable").data
MODELS_CACHE = AI_CORE_PATH / "models_cache"
DB_PATH = AI_CORE_PATH / "local_qdrant_db"
DIMENSION = 512
COLLECTION_NAME = "bot_tools"

# ä½¿ç”¨ Any ä½œä¸ºè¿è¡Œæ—¶ç±»å‹ï¼Œç±»å‹æ£€æŸ¥å™¨ä¼šä½¿ç”¨ TYPE_CHECKING ä¸­çš„ç±»å‹

embedding_model: "Union[TextEmbedding, None]" = None
client: "Union[AsyncQdrantClient, None]" = None

if enable_ai:
    from fastembed import TextEmbedding
    from qdrant_client import AsyncQdrantClient
    from qdrant_client.models import Distance, PointStruct, VectorParams

    logger.info("ğŸ§  [AI][Embedding] æ­£åœ¨åŠ è½½ Embedding æ¨¡å‹...")

    os.environ["HF_HUB_DOWNLOAD_TIMEOUT"] = "60"

    embedding_model = TextEmbedding(
        model_name="BAAI/bge-small-zh-v1.5",
        cache_dir=str(MODELS_CACHE),
    )
    client = AsyncQdrantClient(path=str(DB_PATH))
else:
    logger.info("ğŸ§  [AI][Embedding] æœªå¯ç”¨ Embedding åŠŸèƒ½ï¼Œå°†è·³è¿‡åŠ è½½æ¨¡å‹, AIåŠŸèƒ½å‡ä¸å¯ç”¨...")


def get_tool_id(tool_name: str) -> str:
    """æ ¹æ®å·¥å…·åç§°ç”Ÿæˆå›ºå®šçš„ UUID ä½œä¸º Qdrant å­˜å‚¨çš„å”¯ä¸€ ID"""
    return str(uuid.uuid5(uuid.NAMESPACE_DNS, tool_name))


def calculate_payload_hash(payload: dict) -> str:
    """è®¡ç®— payload çš„ MD5ï¼Œç”¨äºåˆ¤æ–­å·¥å…·æ˜¯å¦æœ‰è¢«ä¿®æ”¹è¿‡"""
    json_str = json.dumps(payload, sort_keys=True, ensure_ascii=False)
    return hashlib.md5(json_str.encode("utf-8")).hexdigest()


async def init_db():
    if client is None:
        return
    if not await client.collection_exists(COLLECTION_NAME):
        logger.info(f"ğŸ§  [AI][Embedding] åˆå§‹åŒ–æ–°é›†åˆ: {COLLECTION_NAME}")
        await client.create_collection(
            collection_name=COLLECTION_NAME,
            vectors_config=VectorParams(size=DIMENSION, distance=Distance.COSINE),
        )


async def sync_tools_to_db():
    """æ ¸å¿ƒï¼šæ™ºèƒ½åŒæ­¥æœ¬åœ°ä»£ç å­—å…¸ä¸ Qdrant æ•°æ®åº“"""
    if client is None or embedding_model is None:
        logger.debug("ğŸ§  [AI][Embedding] AIåŠŸèƒ½æœªå¯ç”¨ï¼Œè·³è¿‡åŒæ­¥")
        return

    all_tools_metadata = get_registered_tools()

    logger.info("ğŸ§  [AI][Embedding] å¼€å§‹åŒæ­¥å·¥å…·åˆ°æ•°æ®åº“!")

    existing_tools = {}
    next_page_offset = None
    while True:
        records, next_page_offset = await client.scroll(
            collection_name=COLLECTION_NAME,
            limit=100,
            with_payload=True,
            with_vectors=False,
            offset=next_page_offset,
        )
        for record in records:
            if record.payload is None:
                continue
            name = record.payload.get("name")
            if name:
                existing_tools[name] = {
                    "id": record.id,
                    "hash": record.payload.get("_hash"),  # æå–æ—§çš„å“ˆå¸Œå€¼
                }
        if next_page_offset is None:
            break

    # 2. å¯¹æ¯”å·®å¼‚ (Diff)
    points_to_upsert = []
    local_tool_names = set(all_tools_metadata.keys())
    db_tool_names = set(existing_tools.keys())

    for name, raw_data in all_tools_metadata.items():
        # æ¸…ç† payloadï¼šå‰”é™¤ä¸èƒ½è¢« JSON åºåˆ—åŒ–çš„ "func" ç­‰å­—æ®µ
        clean_payload = {k: v for k, v in raw_data.items() if k not in ("func", "check_func", "check_kwargs")}
        current_hash = calculate_payload_hash(clean_payload)

        # å°† hash ä¹Ÿå­˜å…¥ payloadï¼Œä¾›ä¸‹æ¬¡æ¯”å¯¹
        clean_payload["_hash"] = current_hash

        is_new = name not in existing_tools
        is_modified = not is_new and existing_tools[name]["hash"] != current_hash

        if is_new or is_modified:
            action_str = "æ–°å¢" if is_new else "æ›´æ–°"
            logger.info(f"ğŸ§  [AI][Embedding] [{action_str}] å‘ç°å˜åŠ¨: {name}")

            # ä½¿ç”¨ desc ç”Ÿæˆå‘é‡ï¼ˆä¹Ÿå¯ä»¥ç»„åˆ name å’Œ descï¼‰
            text_to_embed = f"{raw_data['name']} - {raw_data['desc']}"
            vector = list(embedding_model.embed([text_to_embed]))[0]

            points_to_upsert.append(PointStruct(id=get_tool_id(name), vector=list(vector), payload=clean_payload))
        else:
            logger.info(f"ğŸ§  [AI][Embedding] [è·³è¿‡] æ— éœ€æ›´æ–°: {name}")

    # æ‰¾å‡ºæœ¬åœ°å·²ç»åˆ é™¤ï¼Œä½†æ•°æ®åº“é‡Œè¿˜åœ¨çš„å·¥å…·ï¼Œæ‰§è¡Œåˆ é™¤
    tools_to_delete_names = db_tool_names - local_tool_names
    tools_to_delete_ids = [existing_tools[n]["id"] for n in tools_to_delete_names]

    if points_to_upsert:
        logger.info(f"ğŸ§  [AI][Embedding] æ­£åœ¨å†™å…¥ {len(points_to_upsert)} ä¸ªå˜åŠ¨åˆ°æ•°æ®åº“...")
        await client.upsert(collection_name=COLLECTION_NAME, points=points_to_upsert)

    if tools_to_delete_ids:
        logger.info(f"ğŸ§  [AI][Embedding] æ¸…ç†è¢«ç§»é™¤çš„å·¥å…·: {tools_to_delete_names}")
        await client.delete(collection_name=COLLECTION_NAME, points_selector=tools_to_delete_ids)

    logger.info("ğŸ§  [AI][Embedding] --- åŒæ­¥å®Œæˆ ---\n")


async def search_tools(query: str, limit: int = 3):
    """æ ¹æ®è‡ªç„¶è¯­è¨€æ„å›¾æ£€ç´¢å…³è”å·¥å…·"""
    if client is None or embedding_model is None:
        raise RuntimeError("AIåŠŸèƒ½æœªå¯ç”¨ï¼Œæ— æ³•æœç´¢å·¥å…·")

    logger.info(f"ğŸ§  [AI][Embedding] æ­£åœ¨æŸ¥è¯¢: {query}")
    query_vec = list(embedding_model.embed([query]))[0]

    response = await client.query_points(
        collection_name=COLLECTION_NAME,
        query=list(query_vec),
        limit=limit,
    )
    return response.points


@on_core_start
async def init_embedding():
    await init_db()
    await sync_tools_to_db()
