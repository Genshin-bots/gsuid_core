import re
import copy
import json
import random
import asyncio
import inspect
from typing import Any, Dict, List, Tuple, Union, Optional, cast
from pathlib import Path

import aiofiles
import tiktoken
from bot import Bot
from PIL import Image
from models import Event
from openai import AsyncOpenAI
from openai.types.chat import ChatCompletion, ChatCompletionMessage, ChatCompletionMessageToolCall

from gsuid_core.logger import logger
from gsuid_core.segment import Message, MessageSegment
from gsuid_core.ai_core.register import get_registered_tools
from gsuid_core.ai_core.ai_config import openai_config
from gsuid_core.utils.resource_manager import RM
from gsuid_core.utils.image.image_tools import image_to_base64

from .models import ToolDef

FileInput = Union[str, Path]
MessageUnion = Union[Dict, Any]


# ä½¿ç”¨ tiktoken è¿›è¡Œç²¾ç¡®çš„ token ä¼°ç®—
def estimate_tokens(msg: MessageUnion, enc: Optional[tiktoken.Encoding] = None) -> int:
    """ä½¿ç”¨ tiktoken ç²¾ç¡®ä¼°ç®—æ¶ˆæ¯çš„ token æ•°"""
    if enc is None:
        # é»˜è®¤ä½¿ç”¨ cl100k_base (gpt-4, gpt-3.5-turbo)
        enc = tiktoken.get_encoding("cl100k_base")

    total_tokens = 0
    content = msg.get("content", "")
    if isinstance(content, str):
        total_tokens = len(enc.encode(content))
    elif isinstance(content, list):
        # å¯¹äºåŒ…å«å›¾ç‰‡ç­‰çš„å¤æ‚å†…å®¹ï¼Œä¼°ç®—ä¸€ä¸ªå›ºå®šå€¼
        for item in content:
            if isinstance(item, dict):
                if item.get("type") == "text":
                    text = item.get("text", "")
                    total_tokens += len(enc.encode(text))
                elif item.get("type") == "image_url":
                    # å›¾ç‰‡ token ä¼°ç®— (gpt-4-vision çº¦ä¸º 85 + 170 * ç“¦ç‰‡æ•°)
                    total_tokens += 255  # ç²—ç•¥ä¼°ç®—

    # ä¸ºæ¯æ¡æ¶ˆæ¯å¢åŠ ç»“æ„åŒ– Token å†—ä½™ï¼ˆrole, name ç­‰å­—æ®µçº¦å  4-5 ä¸ª tokenï¼‰
    return total_tokens + 5 if total_tokens > 0 else 5


class AsyncOpenAISession:
    def __init__(
        self,
        api_key: str,
        model: str = "gpt-4o",
        base_url: str = "",
        system_prompt: Optional[str] = None,
    ):
        self.client = AsyncOpenAI(api_key=api_key, base_url=base_url)
        self.model = model
        # åŸºç¡€äººè®¾ï¼ˆæ‰€æœ‰æ¨¡å¼ä¸‹é€šç”¨çš„éƒ¨åˆ†ï¼‰
        self.base_persona = system_prompt or "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚"
        # å†å²è®°å½•åªä¿å­˜ user å’Œ assistant çš„å¯¹è¯ï¼Œä¸ä¿å­˜ system æ¶ˆæ¯
        self.history = []
        # é…ç½®ï¼šæœ€å¤§å·¥å…·è°ƒç”¨è¿­ä»£æ¬¡æ•°ï¼Œé˜²æ­¢æ— é™å¾ªç¯
        self.max_tool_iterations = 5
        # é…ç½®ï¼šæœ€å¤§å†å² token æ•°é‡ï¼ŒæŒ‰ token è£å‰ªï¼ˆç²—ç•¥ä¼°ç®—ï¼Œæ¯ä¸ªä¸­æ–‡å­—ç¬¦çº¦2-3ä¸ªtokenï¼‰
        self.max_history_tokens = 6000
        # é…ç½®ï¼šOpenAI API æœ€å¤§è¾“å‡º token æ•°
        self.max_tokens = 1800
        # å½“å‰å†å²è®°å½•çš„ token æ•°ï¼Œé¿å…æ¯è½®å…¨é‡é‡æ–°è®¡ç®—
        self.current_token_count = 0
        # åˆå§‹åŒ– tiktoken encoder
        try:
            self.tokenizer = tiktoken.encoding_for_model(model)
        except KeyError:
            # å¦‚æœæ¨¡å‹æœªçŸ¥ï¼Œä½¿ç”¨é»˜è®¤çš„ cl100k_base
            self.tokenizer = tiktoken.get_encoding("cl100k_base")

    def _safe_truncate_history(self) -> None:
        """
        å®‰å…¨æˆªæ–­å†å²è®°å½•ï¼Œé¿å…åˆ‡æ–­å·¥å…·é“¾ã€‚
        ç­–ç•¥ï¼š
        1. æˆå¯¹åˆ é™¤æ¶ˆæ¯ï¼ˆç¡®ä¿ä¸åˆ é™¤å•ä¸ªæ¶ˆæ¯å¯¼è‡´è§’è‰²é”™ä¹±ï¼‰
        2. å¦‚æœé‡åˆ° tool æ¶ˆæ¯ï¼Œå¿…é¡»è¿å¸¦åˆ é™¤å¯¹åº”çš„ assistant tool_call æ¶ˆæ¯
        3. ä¿ç•™è‡³å°‘ä¸€ä¸ªå®Œæ•´çš„å¯¹è¯è½®æ¬¡
        ä¼˜åŒ–ï¼šä½¿ç”¨ self.current_token_count é¿å…æ¯è½®å…¨é‡é‡æ–°è®¡ç®—
        """
        # å¦‚æœè¿˜æ²¡æœ‰è®¡ç®—è¿‡å½“å‰ token æ•°é‡ï¼Œå…ˆè®¡ç®—ä¸€æ¬¡
        if self.current_token_count == 0:
            self.current_token_count = sum(estimate_tokens(msg, self.tokenizer) for msg in self.history)

        while True:
            if self.current_token_count <= self.max_history_tokens or len(self.history) <= 2:
                break

            # æŸ¥æ‰¾å¯ä»¥å®‰å…¨åˆ é™¤çš„æœ€å‰é¢çš„æ¶ˆæ¯ç»„
            # ç­–ç•¥ï¼šæ‰¾åˆ°æœ€æ—©çš„ user æ¶ˆæ¯ï¼Œç„¶ååˆ é™¤ user + åç»­çš„ assistantï¼ˆåŒ…æ‹¬ tool chainï¼‰
            removed_count = 0
            i = 0
            while i < len(self.history) and removed_count == 0:
                msg = self.history[i]
                if isinstance(msg, dict) and msg.get("role") == "user":
                    # æ‰¾åˆ°äº†æœ€æ—©çš„ user æ¶ˆæ¯ï¼Œç°åœ¨éœ€è¦åˆ é™¤è¿™ä¸ª user ä»¥åŠåç»­å…³è”çš„æ¶ˆæ¯
                    # åˆ é™¤ user
                    removed_msg = self.history.pop(i)
                    removed_count += 1
                    self.current_token_count -= estimate_tokens(removed_msg, self.tokenizer)

                    # ç»§ç»­åˆ é™¤åç»­å…³è”çš„ assistant å’Œ tool æ¶ˆæ¯
                    # ç›´åˆ°é‡åˆ°ä¸‹ä¸€ä¸ª user æˆ– history ç»“æŸ
                    while i < len(self.history):
                        next_msg = self.history[i]
                        if isinstance(next_msg, dict) and next_msg.get("role") == "user":
                            # é‡åˆ°ä¸‹ä¸€ä¸ª userï¼Œåœæ­¢åˆ é™¤
                            break

                        # åªè¦ä¸æ˜¯ userï¼Œç»Ÿç»Ÿåˆ æ‰ï¼ˆåŒ…æ‹¬ assistant, toolï¼Œä»¥åŠæ®‹ç•™çš„å…¶ä»–å†…å®¹ï¼‰
                        removed_msg = self.history.pop(i)
                        removed_count += 1
                        self.current_token_count -= estimate_tokens(removed_msg, self.tokenizer)
                        # æ­¤å¤„ä¸éœ€è¦ i += 1ï¼Œå› ä¸º pop åå…ƒç´ è‡ªåŠ¨å‰ç§»
                    break
                i += 1

            if removed_count > 0:
                logger.debug(f"ğŸ§  [AI][OpenAI] å†å²æ¶ˆæ¯ token æ•°è¶…é™ï¼Œå®‰å…¨åˆ é™¤ {removed_count} æ¡æ¶ˆæ¯")
            else:
                # æ— æ³•å®‰å…¨åˆ é™¤ï¼Œç›´æ¥åˆ é™¤æœ€æ—©çš„ä¸€æ¡ï¼ˆä¿åº•ç­–ç•¥ï¼‰
                removed_msg = self.history.pop(0)
                self.current_token_count -= estimate_tokens(removed_msg, self.tokenizer)
                logger.warning(
                    f"ğŸ§  [AI][OpenAI] å†å²æ¶ˆæ¯ token æ•°è¶…é™ï¼Œå¼ºåˆ¶åˆ é™¤æœ€æ—©æ¶ˆæ¯: {removed_msg.get('role', 'unknown')}"
                )

    async def _process_file(self, file_path: FileInput) -> str:
        """
        å†…éƒ¨å‡½æ•°ï¼šè¯»å–æ–‡æœ¬æ–‡ä»¶å†…å®¹ã€‚
        æ³¨æ„ï¼šå¯¹äºé Vision æ¨¡å‹çš„éå›¾ç‰‡æ–‡ä»¶ï¼Œé€šå¸¸æ˜¯å°†å†…å®¹ä½œä¸º Context æ”¾å…¥ Promptã€‚
        """
        path = Path(file_path)
        if not path.exists():
            return f"[System Error: File {path.name} not found]"

        try:
            async with aiofiles.open(path, "r", encoding="utf-8") as f:
                content = await f.read()
            return f"\n--- File Content: {path.name} ---\n{content}\n----------------\n"
        except UnicodeDecodeError:
            return f"[System Error: File {path.name} is binary or not UTF-8 text, cannot read directly.]"

    async def chat(
        self,
        text: str = "",
        image_ids: Optional[Union[str, List[str]]] = None,
        files: Optional[Union[FileInput, List[FileInput]]] = None,
        tools: Optional[List[ToolDef]] = None,
        json_mode: bool = False,
        bot: Optional[Bot] = None,
        ev: Optional[Event] = None,
        temp_system: Optional[str] = None,
        user_context: Optional[str] = None,
    ) -> Union[List[Message], dict]:
        # 1. å‡†å¤‡æ¶ˆæ¯å†…å®¹åˆ—è¡¨ (content)
        content_payload = []

        if files:
            if not isinstance(files, list):
                files = [files]
            for f in files:
                # å‡è®¾ _process_file è¿”å›çš„æ˜¯æ–‡æœ¬å­—ç¬¦ä¸²
                file_text = await self._process_file(f)
                text += file_text

        if text:
            if ev:
                for i in ev.image_id_list:
                    text += f"\n--- Upload Image ID: {i} ---\n"

            content_payload.append({"type": "text", "text": text})

        if image_ids:
            images = [await RM.get(_id) for _id in image_ids]

            for img_input in images:
                base64_url = image_to_base64(img_input)

                if base64_url:
                    content_payload.append(
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": base64_url,
                                # "detail": "auto" # å¯é€‰ï¼šæ§åˆ¶å›¾ç‰‡è§£æç²¾åº¦
                            },
                        }
                    )

        # --- D. å¤„ç† JSON æç¤º ---
        # å¦‚æœå¼€å¯ JSON æ¨¡å¼ï¼Œä¸ºäº†é˜²æ­¢æŠ¥é”™ï¼Œç¡®ä¿ Prompt é‡ŒåŒ…å« "JSON"
        if json_mode:
            # æ£€æŸ¥å½“å‰ payload é‡Œæ˜¯å¦æœ‰æ–‡æœ¬æç¤º
            has_json_in_text = False
            for item in content_payload:
                if item["type"] == "text" and "json" in item["text"].lower():
                    has_json_in_text = True
                    break

            if not has_json_in_text:
                content_payload.append({"type": "text", "text": "\n(Please strictly respond in JSON format)"})

        # --- ç©ºå†…å®¹æ£€æŸ¥ ---
        if not content_payload:
            raise ValueError("[AI] Empty input (no text or images provided).")

        # 2. åŠ¨æ€ç»„è£…æœ€ç»ˆå‘é€ç»™ API çš„æ¶ˆæ¯åˆ—è¡¨
        # ç»„è£…æœ€ç»ˆçš„ System Prompt = åŸºç¡€äººè®¾ + å½“å‰æ„å›¾ä¸“å±è§„åˆ™
        # æ³¨æ„ï¼šRAG å‚è€ƒèµ„æ–™åº”è¯¥é€šè¿‡ user_context å‚æ•°æ”¾åœ¨ç”¨æˆ·æ¶ˆæ¯ä¸­ï¼Œè€Œä¸æ˜¯ system prompt
        final_system_content = self.base_persona
        if temp_system:
            final_system_content = f"{self.base_persona}\n\n{temp_system}"

        # æ„å»ºå†å²è®°å½•ä¸“ç”¨çš„ User æ¶ˆæ¯ï¼ˆå¹²å‡€çš„ï¼Œæ—  RAG èµ„æ–™ï¼‰
        history_user_msg = {"role": "user", "content": copy.deepcopy(content_payload)}

        # æ„å»ºå‘ç»™ API çš„ User æ¶ˆæ¯ï¼ˆåŒ…å«æœ¬è½® RAG èµ„æ–™ï¼‰
        api_user_msg_content = copy.deepcopy(content_payload)
        if user_context:
            # æ‰¾åˆ° text èŠ‚ç‚¹å¹¶æ³¨å…¥ RAG
            for item in api_user_msg_content:
                if item["type"] == "text":
                    item["text"] = f"{user_context}\n\n--- ç”¨æˆ·é—®é¢˜ ---\n{item['text']}"
                    break

        current_api_user_msg = {"role": "user", "content": api_user_msg_content}

        api_messages = [{"role": "system", "content": final_system_content}]
        # åŠ ä¸Šå†å²è®°å¿†ï¼ˆè®©å¤§æ¨¡å‹çŸ¥é“ä¸Šæ–‡ï¼‰
        api_messages.extend(self.history)
        # åŠ ä¸Šç”¨æˆ·è¿™ä¸€è½®çš„æœ€æ–°é—®é¢˜ï¼ˆå¸¦ RAG çš„ç‰ˆæœ¬ï¼‰
        api_messages.append(current_api_user_msg)

        tools_reply: List[Message] = []

        # ä¸´æ—¶çš„ä½¿ç”¨ä¸­çš„æ¶ˆæ¯åˆ—è¡¨ï¼ˆç”¨äºå·¥å…·è°ƒç”¨çš„ä¸Šä¸‹æ–‡ï¼‰
        working_messages: List[MessageUnion] = api_messages.copy()

        # è®°å½•åˆå§‹é•¿åº¦ï¼ˆæ­¤æ—¶åŒ…å«äº† current_api_user_msgï¼‰
        initial_working_length = len(working_messages)

        # å·¥å…·è°ƒç”¨è¿­ä»£è®¡æ•°å™¨ï¼Œé˜²æ­¢æ— é™å¾ªç¯
        iteration_count = 0
        # JSON è§£æé”™è¯¯æ¬¡æ•°è®¡æ•°å™¨ï¼Œé˜²æ­¢æ— é™è‡ªæˆ‘ä¿®å¤å¾ªç¯
        json_error_count = 0

        while True:
            # æ£€æŸ¥æœ€å¤§è¿­ä»£æ¬¡æ•°
            iteration_count += 1
            if iteration_count > self.max_tool_iterations:
                logger.warning(f"ğŸ§  [AI][OpenAI] å·¥å…·è°ƒç”¨æ¬¡æ•°è¶…è¿‡æœ€å¤§é™åˆ¶ {self.max_tool_iterations}ï¼Œç»ˆæ­¢å¾ªç¯")
                raise RuntimeError(f"Tool call exceeded max depth of {self.max_tool_iterations}")

            # 3. åœ¨å¾ªç¯å†…é‡å»º request_kwargsï¼Œé¿å…çŠ¶æ€æ±¡æŸ“
            # ç¡®ä¿å‘é€ç»™ API çš„æ¶ˆæ¯ä¸åŒ…å«éæ³•å­—æ®µï¼ˆå¦‚ _turn_idï¼‰
            sanitized_messages = []
            for msg in working_messages:
                if isinstance(msg, dict):
                    # ç§»é™¤æ‰€æœ‰ OpenAI API ä¸å…è®¸çš„å­—æ®µ
                    sanitized_msg = msg.copy()
                    # åªä¿ç•™ OpenAI API å…è®¸çš„å­—æ®µ
                    allowed_fields = {"role", "content", "name", "tool_calls", "tool_call_id"}
                    for key in list(sanitized_msg.keys()):
                        if key not in allowed_fields:
                            del sanitized_msg[key]
                    sanitized_messages.append(sanitized_msg)
                else:
                    # å¦‚æœä¸æ˜¯å­—å…¸ï¼Œç›´æ¥æ·»åŠ 
                    sanitized_messages.append(msg)

            request_kwargs = {
                "model": self.model,
                "messages": sanitized_messages,
                "max_tokens": self.max_tokens,
            }

            if json_mode:
                request_kwargs["response_format"] = {"type": "json_object"}

            if tools:
                request_kwargs["tools"] = tools
                request_kwargs["tool_choice"] = "auto"

            response: ChatCompletion = await self.client.chat.completions.create(**request_kwargs)
            message: ChatCompletionMessage = response.choices[0].message

            working_messages.append(message.model_dump(exclude_none=True))

            logger.trace(f"ğŸ§  [AI][OpenAI] æ¨¡å‹å›å¤: {message}")

            # --- åˆ†æ”¯ 1: æ¨¡å‹è¯·æ±‚è°ƒç”¨å·¥å…· ---
            if message.tool_calls:
                tool_calls_list = cast(
                    List[ChatCompletionMessageToolCall],
                    message.tool_calls,
                )

                logger.trace(f"ğŸ§  [AI][OpenAI] æ¨¡å‹è¯·æ±‚è°ƒç”¨å·¥å…·: {tool_calls_list}")

                for tool_call in tool_calls_list:
                    func_name = tool_call.function.name
                    args_str = tool_call.function.arguments
                    call_id = tool_call.id

                    logger.debug(f"ğŸ§  [AI][OpenAI] ID {call_id} è°ƒç”¨å·¥å…·: {func_name}, å‚æ•°: {args_str}")

                    function_response = "Error: Function not found"

                    tools_list = get_registered_tools()

                    if func_name in tools_list:
                        try:
                            tool_def = tools_list[func_name]
                            # 1. è§£æå‚æ•°ï¼ˆæ¸…ç†å¯èƒ½çš„ markdown æ ‡è®°ï¼‰
                            clean_args_str = re.sub(r"^```(?:json)?\n?|```$", "", args_str.strip(), flags=re.MULTILINE)
                            try:
                                func_args = json.loads(clean_args_str)
                            except json.JSONDecodeError as e:
                                json_error_count += 1
                                # å·§å¦™åˆ©ç”¨ Tool Response è®© AI çŸ¥é“è‡ªå·±é”™äº†å¹¶é‡è¯•
                                function_response = (
                                    f"JSONè§£æé”™è¯¯: {str(e)}ã€‚è¯·ä¸è¦è¾“å‡ºä»»ä½•markdownæ ‡è®°ï¼Œä»…è¾“å‡ºçº¯JSONå¯¹è±¡ã€‚"
                                )
                                working_messages.append(
                                    {
                                        "tool_call_id": call_id,
                                        "role": "tool",
                                        "name": func_name,
                                        "content": function_response,
                                    }
                                )
                                # JSON è§£æé”™è¯¯è¶…è¿‡ 2 æ¬¡ï¼Œåœæ­¢é‡è¯•
                                if json_error_count >= 2:
                                    logger.warning("ğŸ§  [AI][OpenAI] JSON è§£æé”™è¯¯æ¬¡æ•°è¶…é™ï¼Œåœæ­¢å·¥å…·è°ƒç”¨")
                                    continue
                                continue
                            # 2. æŸ¥æ‰¾å‡½æ•°
                            func_obj = tool_def["func"]

                            logger.debug(f"ğŸ§  [AI][OpenAI] ID {call_id} å³å°†æ‰§è¡Œå·¥å…·: {func_name}, å‚æ•°: {func_args}")

                            # 3. æ£€æŸ¥ç¡®è®¤å‡½æ•°ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                            check_func = tool_def.get("check_func")
                            check_kwargs = tool_def.get("check_kwargs", {})

                            logger.debug(
                                f"ğŸ§  [AI][OpenAI] ID {call_id} æ£€æŸ¥å·¥å…·å‰ç½®æ¡ä»¶: {check_func}, å‚æ•°: {check_kwargs}"
                            )

                            if check_func is not None and bot is not None and ev is not None:
                                # æ£€æŸ¥ check_func çš„ç­¾åï¼Œæ ¹æ®å‚æ•°åå’Œç±»å‹æ³¨è§£æ³¨å…¥ä¾èµ–
                                sig = inspect.signature(check_func)
                                check_args = {}

                                for param_name, param in sig.parameters.items():
                                    # æ ¹æ®å‚æ•°åæ³¨å…¥
                                    if param_name == "bot":
                                        check_args[param_name] = bot
                                    elif param_name == "ev" or param_name == "event":
                                        check_args[param_name] = ev
                                    # æ ¹æ®ç±»å‹æ³¨è§£æ³¨å…¥
                                    elif param.annotation != inspect.Parameter.empty:
                                        # è·å–ç±»å‹æ³¨è§£çš„å­—ç¬¦ä¸²è¡¨ç¤º
                                        ann = param.annotation
                                        # å¤„ç† Optional[Type] æˆ– Union[Type, None]
                                        origin = getattr(ann, "__origin__", None)
                                        if origin is not None:
                                            # è·å– Optional å†…éƒ¨çš„çœŸå®ç±»å‹
                                            args = getattr(ann, "__args__", ())
                                            if args and len(args) > 0:
                                                ann = args[0]

                                        ann_str = str(ann)
                                        if "Bot" in ann_str:
                                            check_args[param_name] = bot
                                        elif "Event" in ann_str:
                                            check_args[param_name] = ev

                                check_args.update(check_kwargs)

                                # æ‰§è¡Œç¡®è®¤å‡½æ•°
                                if asyncio.iscoroutinefunction(check_func):
                                    check_passed: Union[bool, Tuple[bool, str]] = await check_func(**check_args)
                                else:
                                    check_passed = check_func(**check_args)

                                logger.debug(f"ğŸ§  [AI][OpenAI] ID {call_id} æ£€æŸ¥ç»“æœ: {check_passed}")

                                if isinstance(check_passed, tuple):
                                    check_passed, reason = check_passed
                                    await bot.send(reason)
                                else:
                                    check_passed = bool(check_passed)
                                    reason = "é”™è¯¯: æƒé™æ£€æŸ¥æœªé€šè¿‡"

                                if not check_passed:
                                    function_response = f"{reason}"
                                    # è·³è¿‡å‡½æ•°æ‰§è¡Œï¼Œç»§ç»­ä¸‹ä¸€ä¸ªå·¥å…·è°ƒç”¨
                                    working_messages.append(
                                        {
                                            "tool_call_id": call_id,
                                            "role": "tool",
                                            "name": func_name,
                                            "content": function_response,
                                        }
                                    )
                                    continue

                            # 5. æ‰§è¡Œå‡½æ•° (å…¼å®¹ async å’Œ sync) - æ·»åŠ ä¾èµ–æ³¨å…¥
                            inject_args = func_args.copy()
                            sig = inspect.signature(func_obj)
                            for param_name, param in sig.parameters.items():
                                if param_name not in inject_args:  # ä¸è¦†ç›–å¤§æ¨¡å‹ä¼ çš„å‚æ•°
                                    if param_name in ("bot",):
                                        inject_args[param_name] = bot
                                    elif param_name in ("ev", "event"):
                                        inject_args[param_name] = ev

                            if asyncio.iscoroutinefunction(func_obj):
                                result = await func_obj(**inject_args)
                            else:
                                result = func_obj(**inject_args)

                            # 6. åºåˆ—åŒ–ç»“æœ
                            if isinstance(result, Message):
                                function_response = "ç”Ÿæˆå†…å®¹æˆåŠŸ, å·²ç»å‘é€äº†ç›¸å…³æ¶ˆæ¯ï¼"
                                tools_reply.append(result)
                            elif isinstance(result, str):
                                function_response = result
                                tools_reply.append(MessageSegment.text(function_response))
                            elif isinstance(result, dict):
                                function_response = json.dumps(result, ensure_ascii=False)
                            elif isinstance(result, bytes):
                                function_response = f"ç”Ÿæˆäº†æŸé¡¹èµ„æº, èµ„æºID: {RM.register(result)}"
                                tools_reply.append(MessageSegment.image(result))
                            elif isinstance(result, list):
                                function_response = json.dumps(result, ensure_ascii=False)
                            elif isinstance(result, Image.Image):
                                function_response = f"ç”Ÿæˆäº†ä¸€å¼ å›¾ç‰‡, å›¾ç‰‡ID: {RM.register(result)}"
                                tools_reply.append(MessageSegment.image(result))
                            else:
                                function_response = str(result)

                        except Exception as e:
                            function_response = f"Error executing {func_name}: {str(e)}"

                    # å°†å·¥å…·ç»“æœä½œä¸º tool message å­˜å…¥ä¸´æ—¶æ¶ˆæ¯åˆ—è¡¨ï¼ˆä¸å­˜å…¥æ°¸ä¹…å†å²ï¼‰
                    working_messages.append(
                        {"tool_call_id": call_id, "role": "tool", "name": func_name, "content": function_response}
                    )

                request_kwargs["messages"] = working_messages
                continue  # ç»§ç»­ä¸‹ä¸€è½®å¾ªç¯ï¼Œè®© AI è¯»å–å·¥å…·ç»“æœå¹¶ç”Ÿæˆæœ€ç»ˆå›å¤

            else:
                content = message.content or ""

                # 4. ä¿å­˜å†å²è®°å½• - å°†çœŸå®çš„ï¼ˆæ— RAGï¼‰User æ¶ˆæ¯ä¸æœ¬è½® AI å›å¤åˆå¹¶
                new_history_messages = [history_user_msg] + working_messages[initial_working_length:]

                # å¯¹ user æ¶ˆæ¯è¿›è¡Œå›¾ç‰‡é™ç»´å­˜å‚¨ï¼ˆé˜²æ­¢å›¾ç‰‡æŠŠ Token æ’‘çˆ†ï¼‰
                for msg in new_history_messages:
                    if isinstance(msg, dict) and msg.get("role") == "user":
                        msg_content = msg.get("content")
                        if isinstance(msg_content, list):
                            # å¯¹ content_payload è¿›è¡Œé™ç»´
                            history_payload = []
                            for item in msg_content:
                                if isinstance(item, dict):
                                    if item.get("type") == "text":
                                        history_payload.append(item)
                                    elif item.get("type") == "image_url":
                                        history_payload.append({"type": "text", "text": "[ç”¨æˆ·ä¸Šä¼ äº†ä¸€å¼ å›¾ç‰‡]"})
                            msg["content"] = history_payload

                # å°†æœ¬è½®æ–°å¢çš„æ¶ˆæ¯è¿½åŠ åˆ° self.history ä¸­ï¼Œå¹¶æ›´æ–° token è®¡æ•°
                for msg in new_history_messages:
                    self.history.append(msg)
                    self.current_token_count += estimate_tokens(msg, self.tokenizer)

                logger.debug(f"ğŸ§  [AI][OpenAI] å†å²è®°å½•å·²æ›´æ–°ï¼Œæ–°å¢ {len(new_history_messages)} æ¡æ¶ˆæ¯")

                # 2. ä¿®æ”¹ history è£å‰ªé€»è¾‘ï¼Œå®‰å…¨æˆªæ–­é¿å…åˆ‡æ–­å·¥å…·é“¾
                self._safe_truncate_history()

                # --- è¿”å›ç»“æœå¤„ç† ---
                if json_mode:
                    try:
                        return json.loads(content)
                    except json.JSONDecodeError:
                        logger.error(f"JSON è§£æå¤±è´¥: {content}")
                        return {"error": "JSONè§£æå¤±è´¥", "raw": content}

                if content:
                    tools_reply.append(MessageSegment.text(content))

                if not tools_reply:
                    # å¦‚æœå·¥å…·æ²¡äº§ç”Ÿå¯è§è¾“å‡ºï¼Œå¤§æ¨¡å‹ä¹Ÿæ²¡è¯´è¯çš„ä¿åº•æªæ–½
                    return [MessageSegment.text("æ‰§è¡Œå®Œæ¯•ã€‚")]

                return tools_reply

    def reset_session(self, system_prompt: Optional[str] = None):
        """é‡ç½®ä¼šè¯ï¼Œå¯é€‰æ‹©æ€§æ›´æ–°åŸºç¡€äººè®¾"""
        self.history = []
        self.current_token_count = 0
        # é‡æ–°åˆå§‹åŒ– tokenizerï¼Œé˜²æ­¢ç¼“å­˜é—®é¢˜
        try:
            self.tokenizer = tiktoken.encoding_for_model(self.model)
        except KeyError:
            self.tokenizer = tiktoken.get_encoding("cl100k_base")
        if system_prompt:
            self.base_persona = system_prompt


# å·¥å‚å‡½æ•°ï¼Œå¯¹å¤–æä¾›ç®€å•çš„å…¥å£
def create_ai_session(
    system_prompt: Optional[str] = None,
    model: Optional[str] = None,
) -> AsyncOpenAISession:
    api_keys: List[str] = openai_config.get_config("api_key").data
    if not api_keys or len(api_keys[0]) <= 6:
        raise ValueError("æœªé…ç½®OpenAI API key æˆ– é…ç½®é”™è¯¯, è¯·æ£€æŸ¥é…ç½®æ–‡ä»¶")
    api_key = random.choice(api_keys)

    if model is None:
        model = openai_config.get_config("model").data
        if not model:
            raise ValueError("æœªé…ç½®OpenAI model æˆ– é…ç½®é”™è¯¯, è¯·æ£€æŸ¥é…ç½®æ–‡ä»¶")

    return AsyncOpenAISession(
        api_key=api_key,
        system_prompt=system_prompt,
        model=model,
        base_url=openai_config.get_config("base_url").data,
    )
