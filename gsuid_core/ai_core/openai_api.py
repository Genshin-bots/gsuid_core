import io
import json
import base64
import random
import asyncio
import inspect
import mimetypes
from typing import List, Tuple, Union, Optional, cast
from pathlib import Path

import aiofiles
from bot import Bot
from PIL import Image
from models import Event
from openai import AsyncOpenAI
from ai_core.models import ToolDef
from openai.types.chat import ChatCompletion, ChatCompletionMessage, ChatCompletionMessageToolCall

from gsuid_core.logger import logger
from gsuid_core.segment import Message, MessageSegment
from gsuid_core.ai_core.register import get_registered_tools
from gsuid_core.ai_core.ai_config import openai_config
from gsuid_core.utils.resource_manager import RM

# å®šä¹‰ç±»åž‹åˆ«åï¼Œæ–¹ä¾¿é˜…è¯»
ImageInput = Union[str, Path, bytes, io.BytesIO, Image.Image]
FileInput = Union[str, Path]


class AsyncOpenAISession:
    def __init__(
        self,
        api_key: str,
        model: str = "gpt-4o",
        base_url: str = "",
        system_prompt: Optional[str] = None,
    ):
        self.client = AsyncOpenAI(api_key=api_key, base_url=base_url)
        self.model = model
        self.history = []
        if system_prompt:
            self.history.append({"role": "system", "content": system_prompt})

    async def _process_image(self, image: ImageInput) -> str:
        """
        å†…éƒ¨å‡½æ•°ï¼šå°†å„ç§ç±»åž‹çš„å›¾ç‰‡è¾“å…¥è½¬æ¢ä¸º Base64 å­—ç¬¦ä¸²
        """
        img_byte_arr = io.BytesIO()
        mime_type = "image/png"  # é»˜è®¤

        try:
            # 1. å¤„ç† PIL Image å¯¹è±¡
            if isinstance(image, Image.Image):
                # è½¬æ¢ RGBA åˆ° RGB (å¦‚æžœå­˜ä¸º JPEG)
                if image.mode in ("RGBA", "P"):
                    image = image.convert("RGB")
                image.save(img_byte_arr, format="PNG")

            # 2. å¤„ç† è·¯å¾„ (str æˆ– Path)
            elif isinstance(image, (str, Path)):
                path = Path(image)
                if not path.exists():
                    raise FileNotFoundError(f"Image not found: {path}")
                mime_type = mimetypes.guess_type(path)[0] or "image/png"
                async with aiofiles.open(path, "rb") as f:
                    img_byte_arr.write(await f.read())

            # 3. å¤„ç† Bytes / BytesIO
            elif isinstance(image, (bytes, io.BytesIO)):
                data = image if isinstance(image, bytes) else image.getvalue()
                img_byte_arr.write(data)
                # å°è¯•ç”¨ PIL æ‰“å¼€ä¸€ä¸‹ä»¥ç¡®è®¤æ ¼å¼ï¼ˆå¯é€‰ï¼Œä¸ºäº†ç¨³å¥æ€§ï¼‰
                try:
                    Image.open(io.BytesIO(data)).verify()
                except Exception:
                    pass

            else:
                raise ValueError(f"Unsupported image type: {type(image)}")

            base64_data = base64.b64encode(img_byte_arr.getvalue()).decode("utf-8")
            return f"data:{mime_type};base64,{base64_data}"

        except Exception as e:
            logger.error(f"Error processing image: {e}")
            return ""

    async def _process_file(self, file_path: FileInput) -> str:
        """
        å†…éƒ¨å‡½æ•°ï¼šè¯»å–æ–‡æœ¬æ–‡ä»¶å†…å®¹ã€‚
        æ³¨æ„ï¼šå¯¹äºŽéž Vision æ¨¡åž‹çš„éžå›¾ç‰‡æ–‡ä»¶ï¼Œé€šå¸¸æ˜¯å°†å†…å®¹ä½œä¸º Context æ”¾å…¥ Promptã€‚
        """
        path = Path(file_path)
        if not path.exists():
            return f"[System Error: File {path.name} not found]"

        try:
            async with aiofiles.open(path, "r", encoding="utf-8") as f:
                content = await f.read()
            return f"\n--- File Content: {path.name} ---\n{content}\n----------------\n"
        except UnicodeDecodeError:
            return f"[System Error: File {path.name} is binary or not UTF-8 text, cannot read directly.]"

    async def chat(
        self,
        text: str = "",
        images: Optional[Union[ImageInput, List[ImageInput]]] = None,
        files: Optional[Union[FileInput, List[FileInput]]] = None,
        tools: Optional[List[ToolDef]] = None,
        json_mode: bool = False,
        bot: Optional[Bot] = None,
        ev: Optional[Event] = None,
    ) -> List[Message]:
        # 1. å‡†å¤‡æ¶ˆæ¯å†…å®¹åˆ—è¡¨ (content)
        content_payload = []

        if files:
            if not isinstance(files, list):
                files = [files]
            for f in files:
                # å‡è®¾ _process_file è¿”å›žçš„æ˜¯æ–‡æœ¬å­—ç¬¦ä¸²
                file_text = await self._process_file(f)
                text += file_text

        if text:
            if ev:
                for i in ev.image_id_list:
                    text += f"\n--- Upload Image ID: {i} ---\n"
            content_payload.append({"type": "text", "text": text})

        if images:
            if not isinstance(images, list):
                images = [images]

            for img_input in images:
                base64_url = await self._process_image(img_input)

                if base64_url:
                    content_payload.append(
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": base64_url,
                                # "detail": "auto" # å¯é€‰ï¼šæŽ§åˆ¶å›¾ç‰‡è§£æžç²¾åº¦
                            },
                        }
                    )

        # --- D. å¤„ç† JSON æç¤º ---
        # å¦‚æžœå¼€å¯ JSON æ¨¡å¼ï¼Œä¸ºäº†é˜²æ­¢æŠ¥é”™ï¼Œç¡®ä¿ Prompt é‡ŒåŒ…å« "JSON"
        if json_mode:
            # æ£€æŸ¥å½“å‰ payload é‡Œæ˜¯å¦æœ‰æ–‡æœ¬æç¤º
            has_json_in_text = False
            for item in content_payload:
                if item["type"] == "text" and "json" in item["text"].lower():
                    has_json_in_text = True
                    break

            if not has_json_in_text:
                content_payload.append({"type": "text", "text": "\n(Please strictly respond in JSON format)"})

        # --- ç©ºå†…å®¹æ£€æŸ¥ ---
        if not content_payload:
            raise ValueError("[AI] Empty input (no text or images provided).")

        # 2. æ›´æ–°ç”¨æˆ·åŽ†å²
        self.history.append({"role": "user", "content": content_payload})

        # 3. å‡†å¤‡è¯·æ±‚å‚æ•°
        request_kwargs = {
            "model": self.model,
            "messages": self.history,
        }

        if json_mode:
            request_kwargs["response_format"] = {"type": "json_object"}

        if tools:
            request_kwargs["tools"] = tools
            request_kwargs["tool_choice"] = "auto"

        tools_reply: List[Message] = []

        while True:
            response: ChatCompletion = await self.client.chat.completions.create(**request_kwargs)
            message: ChatCompletionMessage = response.choices[0].message

            self.history.append(message)

            logger.trace(f"ðŸ§  [AI][OpenAI] æ¨¡åž‹å›žå¤: {message}")

            # --- åˆ†æ”¯ 1: æ¨¡åž‹è¯·æ±‚è°ƒç”¨å·¥å…· ---
            if message.tool_calls:
                tool_calls_list = cast(
                    List[ChatCompletionMessageToolCall],
                    message.tool_calls,
                )

                for tool_call in tool_calls_list:
                    func_name = tool_call.function.name
                    args_str = tool_call.function.arguments
                    call_id = tool_call.id

                    logger.debug(f"ðŸ§  [AI][OpenAI] ID {call_id} è°ƒç”¨å·¥å…·: {func_name}, å‚æ•°: {args_str}")

                    function_response = "Error: Function not found"

                    tools_list = get_registered_tools()

                    if func_name in tools_list:
                        try:
                            tool_def = tools_list[func_name]
                            # 1. è§£æžå‚æ•°
                            func_args = json.loads(args_str)
                            # 2. æŸ¥æ‰¾å‡½æ•°
                            func_obj = tool_def["func"]

                            logger.debug(f"ðŸ§  [AI][OpenAI] ID {call_id} å³å°†æ‰§è¡Œå·¥å…·: {func_name}, å‚æ•°: {func_args}")

                            # 3. æ£€æŸ¥ç¡®è®¤å‡½æ•°ï¼ˆå¦‚æžœå­˜åœ¨ï¼‰
                            check_func = tool_def.get("check_func")
                            check_kwargs = tool_def.get("check_kwargs", {})

                            logger.debug(
                                f"ðŸ§  [AI][OpenAI] ID {call_id} æ£€æŸ¥å·¥å…·å‰ç½®æ¡ä»¶: {check_func}, å‚æ•°: {check_kwargs}"
                            )

                            if check_func is not None and bot is not None and ev is not None:
                                # æ£€æŸ¥ check_func çš„ç­¾åï¼Œæ ¹æ®å‚æ•°åå’Œç±»åž‹æ³¨è§£æ³¨å…¥ä¾èµ–
                                sig = inspect.signature(check_func)
                                check_args = {}

                                for param_name, param in sig.parameters.items():
                                    # æ ¹æ®å‚æ•°åæ³¨å…¥
                                    if param_name == "bot":
                                        check_args[param_name] = bot
                                    elif param_name == "ev" or param_name == "event":
                                        check_args[param_name] = ev
                                    # æ ¹æ®ç±»åž‹æ³¨è§£æ³¨å…¥
                                    elif param.annotation != inspect.Parameter.empty:
                                        # èŽ·å–ç±»åž‹æ³¨è§£çš„å­—ç¬¦ä¸²è¡¨ç¤º
                                        ann = param.annotation
                                        # å¤„ç† Optional[Type] æˆ– Union[Type, None]
                                        origin = getattr(ann, "__origin__", None)
                                        if origin is not None:
                                            # èŽ·å– Optional å†…éƒ¨çš„çœŸå®žç±»åž‹
                                            args = getattr(ann, "__args__", ())
                                            if args and len(args) > 0:
                                                ann = args[0]

                                        ann_str = str(ann)
                                        if "Bot" in ann_str:
                                            check_args[param_name] = bot
                                        elif "Event" in ann_str:
                                            check_args[param_name] = ev

                                check_args.update(check_kwargs)

                                # æ‰§è¡Œç¡®è®¤å‡½æ•°
                                if asyncio.iscoroutinefunction(check_func):
                                    check_passed: Union[bool, Tuple[bool, str]] = await check_func(**check_args)
                                else:
                                    check_passed = check_func(**check_args)

                                logger.debug(f"ðŸ§  [AI][OpenAI] ID {call_id} æ£€æŸ¥ç»“æžœ: {check_passed}")

                                if isinstance(check_passed, tuple):
                                    check_passed, reason = check_passed
                                    await bot.send(reason)
                                else:
                                    check_passed = bool(check_passed)
                                    reason = "é”™è¯¯: æƒé™æ£€æŸ¥æœªé€šè¿‡"

                                if not check_passed:
                                    function_response = f"{reason}"
                                    # è·³è¿‡å‡½æ•°æ‰§è¡Œï¼Œç»§ç»­ä¸‹ä¸€ä¸ªå·¥å…·è°ƒç”¨
                                    self.history.append(
                                        {
                                            "tool_call_id": call_id,
                                            "role": "tool",
                                            "name": func_name,
                                            "content": function_response,
                                        }
                                    )
                                    continue

                            # 5. æ‰§è¡Œå‡½æ•° (å…¼å®¹ async å’Œ sync)
                            if asyncio.iscoroutinefunction(func_obj):
                                result = await func_obj(**func_args)
                            else:
                                result = func_obj(**func_args)

                            # 6. åºåˆ—åŒ–ç»“æžœ
                            if isinstance(result, Message):
                                function_response = "ç”Ÿæˆå†…å®¹æˆåŠŸ, å·²ç»å‘é€äº†ç›¸å…³æ¶ˆæ¯ï¼"
                                tools_reply.append(result)
                            elif isinstance(result, str):
                                function_response = result
                                tools_reply.append(MessageSegment.text(function_response))
                            elif isinstance(result, dict):
                                function_response = json.dumps(result, ensure_ascii=False)
                            elif isinstance(result, bytes):
                                function_response = f"ç”Ÿæˆäº†æŸé¡¹èµ„æº, èµ„æºID: {RM.register(result)}"
                                tools_reply.append(MessageSegment.image(result))
                            elif isinstance(result, list):
                                function_response = json.dumps(result, ensure_ascii=False)
                            elif isinstance(result, Image.Image):
                                function_response = f"ç”Ÿæˆäº†ä¸€å¼ å›¾ç‰‡, å›¾ç‰‡ID: {RM.register(result)}"
                                tools_reply.append(MessageSegment.image(result))
                            else:
                                function_response = str(result)

                        except Exception as e:
                            function_response = f"Error executing {func_name}: {str(e)}"

                    # å°†å·¥å…·ç»“æžœä½œä¸º tool message å­˜å…¥åŽ†å²
                    self.history.append(
                        {"tool_call_id": call_id, "role": "tool", "name": func_name, "content": function_response}
                    )

                request_kwargs["messages"] = self.history
                continue  # ç»§ç»­ä¸‹ä¸€è½®å¾ªçŽ¯ï¼Œè®© AI è¯»å–å·¥å…·ç»“æžœå¹¶ç”Ÿæˆæœ€ç»ˆå›žå¤

            else:
                content = message.content

                if not content:
                    raise ValueError("Empty content from model.")

                if json_mode:
                    try:
                        return json.loads(content)
                    except json.JSONDecodeError:
                        # å®¹é”™ï¼šå¦‚æžœ JSON è§£æžå¤±è´¥ï¼Œè¿”å›žåŽŸå§‹æ–‡æœ¬æˆ–æŠ¥é”™
                        logger.error(f"JSON è§£æžå¤±è´¥: {content}")
                        return [MessageSegment.text("JSON è§£æžå¤±è´¥")]

                tools_reply.append(MessageSegment.text(content))
                return tools_reply

    def reset_session(self, system_prompt: Optional[str] = None):
        """é‡ç½®ä¼šè¯ï¼Œå¯é€‰æ‹©æ€§æ›´æ–° system prompt"""
        self.history = []
        if system_prompt:
            self.history.append({"role": "system", "content": system_prompt})


# å·¥åŽ‚å‡½æ•°ï¼Œå¯¹å¤–æä¾›ç®€å•çš„å…¥å£
def create_ai_session(
    system_prompt: Optional[str] = None,
    model: Optional[str] = None,
) -> AsyncOpenAISession:
    api_keys: List[str] = openai_config.get_config("api_key").data
    if not api_keys or len(api_keys[0]) <= 6:
        raise ValueError("æœªé…ç½®OpenAI API key æˆ– é…ç½®é”™è¯¯, è¯·æ£€æŸ¥é…ç½®æ–‡ä»¶")
    api_key = random.choice(api_keys)

    if model is None:
        model = openai_config.get_config("model").data
        if not model:
            raise ValueError("æœªé…ç½®OpenAI model æˆ– é…ç½®é”™è¯¯, è¯·æ£€æŸ¥é…ç½®æ–‡ä»¶")

    return AsyncOpenAISession(
        api_key=api_key,
        system_prompt=system_prompt,
        model=model,
        base_url=openai_config.get_config("base_url").data,
    )
